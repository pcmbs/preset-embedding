# @package _global_

defaults:
  - _self_
  - m_preset: mlp_relu_raw
  - sampler: tpe
  - pruner: nop

# TODO: export train dataset change path 
# path_to_train_dataset: ${paths.root_dir}/data/datasets/tal_noisemaker_mn04_size=1000000_seed=300_pkl_hpt-train_1
path_to_train_dataset: ${paths.root_dir}/data/datasets/tal_noisemaker_mn04_size=65536_seed=400_pkl_hpt-val_1
path_to_val_dataset: ${paths.root_dir}/data/datasets/tal_noisemaker_mn04_size=65536_seed=400_pkl_hpt-val_1

# seed for the first run (will be incremented by 1 for each subsequent run)
seed: 42

# number of trials to run
num_trials: 100

# in which direction the objective should be optimized (minimize or maximize)
direction: maximize

# name of the optuna study
study_name: ${m_preset.name}_${sampler.name}_${pruner.name}

# number of workers for the train and val dataloader
num_workers: 8
num_ranks_mrr: 128

# scheduler config for lightning module
scheduler_config: 
  interval: step
  frequency: 1

############ Hyperparameters search space (to be passed to optuna.trial.suggest_*)
# batch size used for training (suggest_categorical)
search_space:
  train_batch_size: 
    - 32
    - 64
    - 128
    - 256
    - 512
    - 1024
    - 2048

  # min/max number of blocks for the preset encoder (suggest_int, linear scale)
  num_blocks: 
    - 1
    - 6

  # min/max number of hidden features for the preset encoder (suggest_int, log scale)
  hidden_features: 
    - 256
    - 2048

  # optimizer (suggest_categorical)
  optimizer_names:
    - Adam
    - NAdam

  # min/max learning rate (suggest_float, log scale)
  learning_rate: 
    - 0.0001 
    - 0.005

  # LR warmup: min/max total number of warmup steps (suggest_int, linear scale)
  lr_warmup_total_iters: 
    - 0
    - 1000

  # LR warmup: min/max start factor (suggest_float, linear scale)
  lr_warmup_start_factor: 
    - 0.05
    - 0.6

############ Hydra stuff
# disable output directory
paths:
  root_dir: ${oc.env:PROJECT_ROOT}
  output_dir: ${hydra:runtime.output_dir}

hydra:
  run:
    dir: ${paths.root_dir}/logs/optuna/${m_preset.name}_${sampler.name}_${pruner.name}_${now:%Y-%m-%d}_${now:%H-%M-%S}
  # sweep:
  #   dir:  ${paths.root_dir}/logs/optuna/${m_preset.name}_${now:%Y-%m-%d}_${now:%H-%M-%S}
  #   subdir: bs=${loader.batch_size}_nb=${m_preset.cfg.num_blocks}_hf=${m_preset.cfg.hidden_features}

  job: 
    chdir: True

  job_logging:
    handlers:
      file:
        filename: ${hydra.runtime.output_dir}/${hydra.job.name}.log
    formatters:
      simple:
        format: '%(message)s'
