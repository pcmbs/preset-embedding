##### Architecture HPs
# number of blocks for the preset encoder (linear scale)
num_blocks: 
  type: int
  kwargs:
    name: num_blocks
    low: 2
    high: 8
    step: 2

# number of hidden features for the preset encoder (linear scale)
hidden_features: 
  type: int
  kwargs:
    name: hidden_features
    low: 256
    high: 256
    step: 1

# number of attention heads for the preset encoder (linear scale)
num_heads: 
  type: int
  kwargs:
    name: num_heads
    low: 4
    high: 8
    step: 4

# factor for the pointwise FFNN inner dimension (linear scale)
mlp_factor: 
  type: int
  kwargs:
    name: mlp_factor
    low: 2
    high: 4
    step: 2


##### scheduler HPs
# switch from constant to cosine decay
# `high` should be set to something like 3/4 * (1e6 * train_dataset_size_factor) // batch_size
# to account for different batch_size and train_dataset_size_factor
milestone:
  type: int
  kwargs:
    name: milestone
    low: 0
    high: 1500

# starting learning rate
base_lr: 
  type: float
  kwargs:
    name: base_lr
    low: 1e-5
    high: 6e-3
    log: true

# scheduler final lr
min_lr:
  type: float
  kwargs:
    name: min_lr
    low: 1e-10
    high: 0.015
    log: true


##### Adam HPs
# Exp decay rate for 1st moment estimate
beta1:
  type: float
  kwargs:
    name: beta1
    low: 0.85
    high: 0.95
    step: 0.001

# Exp decay rate for 1st moment estimate
beta2:
  type: float
  kwargs:
    name: beta2
    low: 0.95
    high: 0.999
    step: 0.001

# epsilon for numerical stability
eps:
  type: float
  kwargs:
    name: eps
    low: 1e-10
    high: 1e-6
    log: true