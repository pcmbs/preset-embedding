# @package _global_

# Here we train 0.1 (1M presets) of the diva training set for 100M
# validation is performed at the end of each training epoch


defaults:
  - override /train_dataset: diva_mn04_v1
  - override /val_dataset: diva_mn04_v1
  - override /m_preset: highway_oh


########## hyperparameters 

m_preset: # 8_584_768 parameters
  cfg:
    hidden_features: 896
    num_blocks: 6

solver:
  lr: 4e-3
  optimizer:
    betas:
      - 0.9
      - 0.979
    eps: 2e-7

  scheduler:
    total_steps: 200_000 # not an HP, must be (num_epochs * num_training_examples) / batch_size
    milestone: 7500
    final_lr: 2e-7

########## training setup
train_dataset:
  loader:
    batch_size: 512

trainer:
  # kwargs for lightning trainer
  max_epochs: 20

  limit_train_batches: 0.5

  val_check_interval: 0.5 # check val set every epoch
  
  # set True to to ensure deterministic results
  # makes training slower but gives more reproducibility than just setting seeds
  deterministic: True
  