# @package _global_

defaults:
  - override /train_dataset: dexed_mn04_v1
  - override /val_dataset: dexed_mn04_v1
  - override /m_preset: highway_oh

task_name: debug

tags:
  - debug

########## hyperparameters 

m_preset: # 6_360_749 parameters
  cfg:
    num_blocks: 6
    hidden_features: 768

solver:
  # _target_: models.lit_module.PresetEmbeddingLitModule.load_from_checkpoint
  # checkpoint_path: ${paths.log_dir}/train/debug_2024-03-28_16-13-24/checkpoints/last.ckpt
  # strict: False

  lr: 4e-3
  optimizer:
    betas:
      - 0.93
      - 0.987
    eps: 2e-7

  scheduler:
    _target_: utils.lr_schedulers.wcrc_scheduler_builder
    _partial_: true
    num_decay_steps: 192_500
    num_warmup_steps: 7500
    # num_restart_steps: 2000
    restart_factor: 0.5
    min_lr: 2e-6

########## training setup
train_dataset:
  loader:
    batch_size: 512
    num_workers: 8

trainer:
  # kwargs for lightning trainer
  max_epochs: 20
  # limit_train_batches: 0.1
  # limit_val_batches: 0.1
  log_every_n_steps: 50
  
  # set True to to ensure deterministic results
  # makes training slower but gives more reproducibility than just setting seeds
  deterministic: True

# reset_optimizer: True
ckpt_path: ${paths.log_dir}/train/dexed_highway_oh_b_ext/checkpoints/last_wcrc.ckpt
  
val_dataset:
  loader:
    num_workers: 8