_target_: models.lit_module.PresetEmbeddingLitModule
_convert_: all # somehow resolves an omegaconf missing key error during trainer.fit setup

wandb_watch_args:
  log: gradients
  log_freq: 100 

loss:
  _target_: torch.nn.L1Loss

optimizer:
  _target_: torch.optim.Adam
  _partial_: true

# Learning Rate
lr: 0.007

# LR scheduler
scheduler:
  _target_: utils.lr_schedulers.lin_cos_scheduler_builder
  _partial_: true
  # total_steps: # should be (num_epochs * num_training_examples) / batch_size
  milestone: 1400
  final_lr: 0.0000001
  linear_start_factor: 1
  linear_end_factor: 1
